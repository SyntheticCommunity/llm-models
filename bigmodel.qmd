# 智谱开放平台

[智谱 AI 开放平台](https://open.bigmodel.cn)提供一系列具有不同功能和定价的大模型，包括通用大模型、超拟人大模型、图像大模型、向量大模型等，并且支持使用您的私有数据对模型进行微调。

## 模型清单

智谱AI 开放平台提供了包括通用大模型、图像大模型、超拟人大模型、向量大模型等多种模型。

### 语言模型

+----------------+------------------------------------------------------------+----------+----------+
| 模型           | 描述                                                       | 上下文   | 最大输出 |
+:===============+:===========================================================+:=========+:=========+
| GLM-4-Plus     | **高智能旗舰**: 性能全面提升，长文本和复杂任务能力显著增强 | 128K     | 4K       |
+----------------+------------------------------------------------------------+----------+----------+
| GLM-4-0520     | **高智能模型**：适用于处理高度复杂和多样化的任务           | 128K     | 4K       |
+----------------+------------------------------------------------------------+----------+----------+
| GLM-4-Long     | **超长输入**：专为处理超长文本和记忆型任务设计             | 1M       | 4K       |
+----------------+------------------------------------------------------------+----------+----------+
| GLM-4-AirX     | **极速推理**：具有超快的推理速度和强大的推理效果           | 8K       | 4K       |
+----------------+------------------------------------------------------------+----------+----------+
| GLM-4-Air      | **高性价比**：推理能力和价格之间最平衡的模型               | 128K     | 4K       |
+----------------+------------------------------------------------------------+----------+----------+
| GLM-4-Flash    | **免费调用**：智谱AI首个免费API，零成本调用大模型。        | 128K     | 4K       |
+----------------+------------------------------------------------------------+----------+----------+
| GLM-4V         | **图像理解**：具备图像理解能力和推理能力                   | 2K       | 1k       |
+----------------+------------------------------------------------------------+----------+----------+
| GLM-4-AllTools | **Agent模型**：自主规划和执行复杂任务                      | 128K     | 4K       |
+----------------+------------------------------------------------------------+----------+----------+
| GLM-4          | **旧版旗舰**：发布于2024年1月16日，目前已被GLM-4-0520取代  | 128K     | 4K       |
+----------------+------------------------------------------------------------+----------+----------+

### 多模态模型

+-------------+--------------------------------------------------------------+----------+-------------+
| 模型        | 描述                                                         | 最大输入 | 输出分辨率  |
+:============+:=============================================================+:=========+:============+
| GLM-4V-Plus | **视频和图像理解**：具备视频内容和多图片的理解能力           | 8K       | \-          |
+-------------+--------------------------------------------------------------+----------+-------------+
| GLM-4V      | **图像理解**：具备图像理解能力和推理能力                     | 2K       | \-          |
+-------------+--------------------------------------------------------------+----------+-------------+
| CogVideoX   | **视频生成**：输入文本或图片即可轻松制作视频                 | 0.5K     | 1440x960    |
+-------------+--------------------------------------------------------------+----------+-------------+
| CogView-3.5 | **图片生成**：根据用户文字描述生成高质量图像，支持多图片尺寸 | 1k       | 1024x1024\  |
|             |                                                              |          | 768x1344\   |
|             |                                                              |          | 864x1152 等 |
+-------------+--------------------------------------------------------------+----------+-------------+
| CogView-3   | **图片生成**：根据用户文字描述快速、精准生成图像             | 1k       | 1024x1024   |
+-------------+--------------------------------------------------------------+----------+-------------+

### 向量模型

+-------------+---------------------------------------+------------+------------+
| 模型        | 描述                                  | 最大输入   | 向量维度   |
+:============+:======================================+:===========+:===========+
| Embedding-3 | **最新模型**：支持自定义向量维度      | 8K         | 2048       |
+-------------+---------------------------------------+------------+------------+
| Embedding-2 | **旧版模型**：目前已被Embedding-3取代 | 8K         | 1024       |
+-------------+---------------------------------------+------------+------------+

### 其他模型

+------------+------------------------------------------------------------------+---------+----------+
| 模型       | 描述                                                             | 上下文  | 最大输出 |
+:===========+:=================================================================+:========+:=========+
| ChatGLM-3  | **拟人模型**：适用于情感陪伴和虚拟角色。                         | 4K      | 2K       |
+------------+------------------------------------------------------------------+---------+----------+
| Emohaa     | **心理模型**：具备专业咨询能力，帮助用户理解情感并应对情绪问题。 | 8K      | 4k       |
+------------+------------------------------------------------------------------+---------+----------+
| CodeGeeX-4 | **代码模型**：适用于代码自动补全任务                             | 128K    | 4k       |
+------------+------------------------------------------------------------------+---------+----------+

::: callout-note
### 关键概念

**GLM**

GLM 全名 General Language Model ，是一款基于自回归填空的预训练语言模型。ChatGLM系列模型，支持相对复杂的自然语言指令，并且能够解决困难的推理类问题。该模型配备了易于使用的 API 接口，允许开发者轻松将其融入各类应用，广泛应用于智能客服、虚拟主播、聊天机器人等诸多领域。

**Embedding**

Embedding 是一种将数据（如文本）转化为向量形式的表示方法，这种表示方式确保了在某些特定方面相似的数据在向量空间中彼此接近，而与之不相关的数据则相距较远。通过将文本字符串转换为向量，使得数据能够有效用于搜索、聚类、推荐系统、异常检测和分类等应用场景。

**Token**

Token 是模型用来表示自然语言文本的基本单位，可以直观的理解为“字”或“词”；通常 1 个中文词语、1 个英文单词、1 个数字或 1 个符号计为 1 个token。

一般情况下 ChatGLM 系列模型中 token 和字数的换算比例约为 1:1.8 ，但因为不同模型的分词不同，所以换算比例也存在差异，每一次实际处理 token 数量以模型返回为准，您可以从返回结果的 usage 中查看。
:::

## 语言模型

GLM-4 提供了多款模型，适用于各种应用场景。

模型编码：`glm-4-plus`、`glm-4-0520`、`glm-4` 、`glm-4-air`、`glm-4-airx`、`glm-4-long`、 `glm-4-flash`。

### 使用 OpenAI SDK

使用 OpenAI SDK 创建 Client，示例如下：

```{python}
from openai import OpenAI
import os

# format output
from IPython.display import Markdown
from pprint import pprint


client = OpenAI(
    api_key= os.getenv("ZHIPUAI_API_KEY"),
    base_url="https://open.bigmodel.cn/api/paas/v4/"
) 
```

以下代码是 GLM-4 的对话调用示例，请注意：

-   `temperature`：参数的区间为 `(0,1)`
-   `do_sample = False (temperature = 0)`：在 OpenAI 调用中并不适用

```{python}
#| output: asis

# 提交对话请求
completion = client.chat.completions.create(
    model="glm-4",
    messages=[
        {
            "role": "system",
            "content": "你是一个聪明且富有创造力的小说作家"
        },
        {
            "role": "user",
            "content": (
                "请你作为童话故事大王，写一篇短篇童话故事，"
                "故事的主题是要永远保持一颗善良的心，要能够"
                "激发儿童的学习兴趣和想象力，同时也能够帮助"
                "儿童更好地理解和接受故事中所蕴含的道理和价值观。"
            )
        }
    ],
    top_p=0.7,
    temperature=0.9
)

print(completion.choices[0].message.content)
```

### 使用智谱AI SDK

使用智谱AI SDK 可以更方便的创建 client 和使用模型提供的附加功能。

```{python}
from zhipuai import ZhipuAI

client = ZhipuAI(api_key=os.getenv("ZHIPUAI_API_KEY")) # 请填写您自己的APIKey

tools = [{
    "type": "web_search",
    "web_search": {
        "enable": True #默认为关闭状态（False） 禁用：False，启用：True。
    }
}]

messages = [{
    "role": "user",
    "content": "中国 2024 年一季度的GDP是多少 "
}]

response = client.chat.completions.create(
    model="glm-4",
    messages=messages,
    tools=tools
)

print(response.choices[0].message)
```

## 多模态模型

### 文生视频

CogVideoX 是由智谱AI开发的视频生成大模型，具备强大的视频生成能力、只需输入文本或图片就可以轻松完成视频制作。本指南将教您如何系统地构建提示词，从而生成专业级别的视频作品。

提示词的精确度与细节水平直接影响视频内容的质量。采用结构化提示词可以极大提升视频内容的符合度和专业性。以下是构建提示词的关键组成部分：

**提示词 = (镜头语言 +景别角度+ 光影) + 主体 (主体描述) + 主体运动 +场景 (场景描述) + (氛围)**

-   镜头语言:通过镜头的各种应用以及镜头之间的衔接和切换来传达故事或信息，并创造出特定的视觉效果和情感氛围。如镜头平移，推近、拉远、升降拍摄、摇摄、跟随拍摄、手持拍摄、无人机航拍等;

-   景别角度：控制相机与被摄对象之间距离和角度，实现不同的视觉效果和情感表达。如大全景、中景、近景 、鸟瞰视角 、跟随视角、鱼眼效果等;

-   光影:光影是赋予摄影作品灵魂的关键元素，光影的运用可以使照片更具深度，更具情感，我们可以通过光影创造出富有层次感和情感表达力的作品。如自然光、丁达尔效应、柔和散射、硬光直射 、逆光剪影、三点布光等;

-   主体:主体是视频中的主要表现对象。如儿童、狮子、向日葵，汽车、城堡等;

-   主体描述:对主体外貌细节和肢体姿态等的描述，如人物的服饰、动物的毛色、植物的颜色、物体的状态和建筑的风格;

-   主体运动:对主体运动状态的描述，包括静止和运动等，运动状态不宜过于复杂，符合6s视频内可以展现的画面即可，

-   场景: 场景是主体所处的环境，包括前景、背景等;

-   场景描述:对主体所处环境的细节描述。如都市环境、乡村风光、工业区等;

-   氛围:对预期视频画面的氛围描述。如喧嚣繁忙、悬疑惊悚、宁静舒适等;

### 图生视频

CogVideoX 可以将用户提供的静态图像转化为 6 秒的动态视频。为达到最佳效果，推荐上传比例为3:2的图片，并且文件格式为 PNG 或 JPEG，文件大小不超过5MB。提示词建议使用“主体（背景）+ 运动描述”的表达方式。

### 文生图片

CogView-3-Plus使用Transformer架构训练扩散模型，优化了效果并验证了参数量提升的效益。我们还构建了高质量图像微调数据集，使模型生成更符合指令且美学评分更高的图像，效果接近MJ-V6和FLUX等一流模型。

### 图片视频理解

GLM-4V-Plus 集图像理解与视频理解能力于一体的多模态模型。

## 增强检索

通过在大语言模型生成答案之前，先从知识库中检索相关知识，然后将相关知识作为背景信息输入给大模型，有效地提升内容的准确性和相关性。

### 创建知识库

用于管理文件，支持上传多个文件，并通过关联知识库 ID 后进行调用。

```{python}
#| eval: false
knowledgeDB = client.knowledge.create(
    embedding_id=3,
    name="default",
    description="the default knowledge database"
)
print(knowledgeDB.id)
```

```{python}
#| echo: false

# 为了避免创建太多 knowledge database，这里使用之前已经建好的。
knowledge_list = client.knowledge.query(
    page=1,
    size=10,
)

knowledgeDB = knowledge_list.list[0]
print(knowledgeDB.id)
```

### 请求知识库文件列表

```{python}
# 请求知识库文件列表
knowledge_files = client.knowledge.document.list(
    purpose="retrieval",   #支持retrieval
    knowledge_id=knowledgeDB.id
)
print(knowledge_files)
```

### 上传文件

支持将doc、docx、pdf、xlsx类型文件上传到知识库，支持自定义文件切片的大小和规则。文件大小不得超过 50 MB，总数为 100 个文件。

``` python
#| output: asis
resp = client.knowledge.document.create(
    file=open("example/Kraken2.pdf", "rb"),
    purpose="retrieval",
    knowledge_id=knowledgeDB.id,
    sentence_size=202,
    custom_separator=["\n"]
)

print(resp)
```

```{python}
#| echo: false

# 模拟打印结果
pprint(knowledge_files.list[0])
```

### 文件内容提取

文件内容提取仅适用于以 `purpose="file-extract"` 为目的上传的文件。

``` python
# 文件内容抽取
file_content = client.files.content(file_id=knowledge_files.list[0].id)
print(file_content)
```

### 检索知识库

```{python}
knowledge_list = client.knowledge.query(
    page=1,
    size=10,
)
pprint(knowledge_list.model_dump())
```

创建知识库后，您将获得一个知识库ID。调用模型服务时，传入知识库ID，使大模型能获取相关内容以响应用户查询。

### 调用知识库

创建知识库后，您将获得一个知识库ID。调用模型服务时，传入知识库ID，使大模型能获取相关内容以响应用户查询。

```{python}
question = "Kraken2的安装方法"
knowledge = "默认知识库"
response = client.chat.completions.create(
    model="glm-4",  # 填写需要调用的模型名称
    messages=[
        {"role": "user", "content": question},
    ],
    tools=[
            {
                "type": "retrieval",
                "retrieval": {
                    "knowledge_id": knowledgeDB.id,
                    "prompt_template": "从文档“{{knowledge}}” 中找问题“{{question}}”的答案，找到答案就仅使用文档语句回答问题，找不到答案就用自身知识回答并且告诉用户该信息不是来自文档。\n不要复述问题，直接开始回答。"
                }
            }
            ],
    stream=False,
)

Markdown(response.choices[0].message.content)
```

### 删除文件

``` python
result = client.files.delete(
    file_id="文件id"      #支持retrieval、batch、fine-tune、file-extract文件
)
```

### 删除知识库

使用下面的语句删除知识库。

``` python
result = client.knowledge.delete(
    knowledge_id="xxxxxxxxxxxx"
)
```

### 用量查询

```{python}
#| output: asis
result = client.knowledge.used()
pprint(result.model_dump_json(), width = 72)
```

## 基于文件的问答

`GLM-4-Long` 最长支持200万字符上下文，结合文件问答功能。

```{python}
from pathlib import Path
import json

# 上传并提取文本内容
file_01 = client.files.create(file=Path("example/Kraken2.pdf"), purpose="file-extract")
content_01 = json.loads(client.files.content(file_01.id).content)["content"]

# 上传并提取文本内容
file_02 = client.files.create(file=Path("example/gaoch-cv.md"), purpose="file-extract")
content_02 = json.loads(client.files.content(file_02.id).content)["content"]

# 生成请求消息，将不同文件的内容放入消息中
message_content = (
    "请对以下论文进行分析，并且生成一份论文综述：\n\n"
    "第一篇论文内容如下：\n"    
    f"{content_01}\n\n"
    "第二篇论文内容如下：\n"
    f"{content_02}"
)

response = client.chat.completions.create(
    model="glm-4-long",  
    messages=[
        {"role": "user", "content": message_content}
    ],
)

print(response.choices[0].message)
```

### 删除文件

请求文件列表，然后利用 `file_id` 删除文件。

```{python}
#| output: asis


# 请求文件列表
result = client.files.list(
    purpose="file-extract",    #支持batch、file-extract、fine-tune
)
pprint(result)
```

``` python
result = client.files.delete(
    file_id="文件id"      #支持retrieval、batch、fine-tune、file-extract文件
)
```
